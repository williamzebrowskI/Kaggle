{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8908307,"sourceType":"datasetVersion","datasetId":5356289}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/william2020/deep-fnn-for-intent-classification?scriptVersionId=187706217\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Deep FNN for Intent Classification: Training, Validating, and Analyzing Misclassifications\n\n### This notebook demonstrates how to train, evaluate, and analyze a neural network model for intent classification using PyTorch and sklearn.","metadata":{}},{"cell_type":"code","source":"!pip install -q torch scikit-learn numpy","metadata":{"execution":{"iopub.status.busy":"2024-07-10T18:44:36.68432Z","iopub.execute_input":"2024-07-10T18:44:36.685175Z","iopub.status.idle":"2024-07-10T18:44:48.610224Z","shell.execute_reply.started":"2024-07-10T18:44:36.685136Z","shell.execute_reply":"2024-07-10T18:44:48.608635Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom kaggle_secrets import UserSecretsClient\nimport numpy as np\nimport os\nimport json","metadata":{"execution":{"iopub.status.busy":"2024-07-10T18:44:48.61274Z","iopub.execute_input":"2024-07-10T18:44:48.613123Z","iopub.status.idle":"2024-07-10T18:44:48.619805Z","shell.execute_reply.started":"2024-07-10T18:44:48.613086Z","shell.execute_reply":"2024-07-10T18:44:48.618758Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"# Grab the intent data from datasets","metadata":{}},{"cell_type":"code","source":"# Load Kaggle dataset path\nkaggle_data_path = \"/kaggle/input/intent-data\"\n\n# Import intent data from the Kaggle dataset\nimport sys\nsys.path.append(kaggle_data_path)\nfrom intents import intent_data","metadata":{"execution":{"iopub.status.busy":"2024-07-10T18:44:48.621402Z","iopub.execute_input":"2024-07-10T18:44:48.621866Z","iopub.status.idle":"2024-07-10T18:44:48.633961Z","shell.execute_reply.started":"2024-07-10T18:44:48.621825Z","shell.execute_reply":"2024-07-10T18:44:48.63289Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"# What's do we have?","metadata":{}},{"cell_type":"code","source":"num_intents = len(intent_data)\nnum_examples = sum(len(examples) for examples in intent_data.values())\n\nprint(f\"Number of intents: {num_intents}\")\nprint(f\"Total number of examples: {num_examples}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-10T18:44:48.636043Z","iopub.execute_input":"2024-07-10T18:44:48.6364Z","iopub.status.idle":"2024-07-10T18:44:48.645266Z","shell.execute_reply.started":"2024-07-10T18:44:48.636371Z","shell.execute_reply":"2024-07-10T18:44:48.644189Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Number of intents: 35\nTotal number of examples: 1910\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Define the Neural Network Model\n## The neural network model for intent classification consists of three fully connected layers with ReLU activations.","metadata":{}},{"cell_type":"code","source":"class IntentClassifierModel(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(IntentClassifierModel, self).__init__()\n        self.fc1 = nn.Linear(input_dim, 128)\n        self.relu1 = nn.ReLU()\n        self.fc2 = nn.Linear(128, 64)\n        self.relu2 = nn.ReLU()\n        self.fc3 = nn.Linear(64, 32)\n        self.relu3 = nn.ReLU()\n        self.fc4 = nn.Linear(32, 16)\n        self.relu4 = nn.ReLU()\n        self.fc5 = nn.Linear(16, output_dim)\n\n    def forward(self, x):\n        out = self.fc1(x)\n        out = self.relu1(out)\n        out = self.fc2(out)\n        out = self.relu2(out)\n        out = self.fc3(out)\n        out = self.relu3(out)\n        out = self.fc4(out)\n        out = self.relu4(out)\n        out = self.fc5(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-07-10T18:00:12.050909Z","iopub.execute_input":"2024-07-10T18:00:12.051263Z","iopub.status.idle":"2024-07-10T18:00:12.061066Z","shell.execute_reply.started":"2024-07-10T18:00:12.051233Z","shell.execute_reply":"2024-07-10T18:00:12.059931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Data\n## We load the intent data, vectorize the texts using TfidfVectorizer, and encode the labels.","metadata":{}},{"cell_type":"code","source":"def load_data(intent_data):\n    vectorizer = TfidfVectorizer()\n    texts = []\n    labels = []\n    original_phrases = []\n    for intent, phrases in intent_data.items():\n        for phrase in phrases:\n            texts.append(phrase)\n            labels.append(intent)\n            original_phrases.append(phrase)\n    X_tfidf = vectorizer.fit_transform(texts).toarray()\n    label_to_index = {label: idx for idx, label in enumerate(intent_data.keys())}\n    y = np.array([label_to_index[label] for label in labels])\n    return X_tfidf, y, vectorizer, label_to_index, original_phrases","metadata":{"execution":{"iopub.status.busy":"2024-07-10T18:00:12.062593Z","iopub.execute_input":"2024-07-10T18:00:12.062972Z","iopub.status.idle":"2024-07-10T18:00:12.072242Z","shell.execute_reply.started":"2024-07-10T18:00:12.062934Z","shell.execute_reply":"2024-07-10T18:00:12.071364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train and Save the Model\n## We define a function to train the model and save its state dictionary.","metadata":{}},{"cell_type":"code","source":"def train_and_save_model(intent_data, model_path):\n    try:\n        # Load data\n        X, y, vectorizer, label_to_index, _ = load_data(intent_data)\n        input_dim = X.shape[1]  # Number of input features\n        output_dim = len(label_to_index)  # Number of output classes\n        \n        # Initialize the model\n        model = IntentClassifierModel(input_dim, output_dim)\n        criterion = nn.CrossEntropyLoss()  # Loss function for classification\n        optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer with learning rate 0.001\n        \n        # Convert data to PyTorch tensors\n        X_tensor = torch.tensor(X, dtype=torch.float32)\n        y_tensor = torch.tensor(y, dtype=torch.long)\n        \n        # Train the model\n        num_epochs = 300  # Number of training epochs\n        for epoch in range(num_epochs):\n            model.train()  # Set the model to training mode\n            optimizer.zero_grad()  # Zero the gradients\n            outputs = model(X_tensor)  # Forward pass\n            loss = criterion(outputs, y_tensor)  # Compute the loss\n            loss.backward()  # Backward pass (compute gradients)\n            optimizer.step()  # Update the weights\n            \n            # Calculate training accuracy\n            _, predicted_train = torch.max(outputs.data, 1)  # Get the index of the max log-probability\n            train_accuracy = accuracy_score(y_tensor, predicted_train)  # Calculate accuracy\n            \n            # Print the loss and accuracy every 10 epochs\n            if (epoch + 1) % 10 == 0:\n                print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}, Training Accuracy: {train_accuracy:.4f}')\n        \n        print('Training completed')\n        # Save the state dictionary of the model\n        torch.save(model.state_dict(), model_path)\n        print(f'Model state dictionary saved to {model_path}')\n        return model, vectorizer, label_to_index\n    \n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return None, None, None","metadata":{"execution":{"iopub.status.busy":"2024-07-10T18:01:16.990315Z","iopub.execute_input":"2024-07-10T18:01:16.990791Z","iopub.status.idle":"2024-07-10T18:01:17.001658Z","shell.execute_reply.started":"2024-07-10T18:01:16.990753Z","shell.execute_reply":"2024-07-10T18:01:17.000388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validate the Model\n## We define a function to validate the model, log misclassified examples, and save them to a JSON file.","metadata":{}},{"cell_type":"code","source":"def validate_model(model, X_test, y_test, label_to_index, vectorizer, original_phrases, output_json_path):\n    model.eval()\n    misclassified_examples = []\n    with torch.no_grad():\n        X_tensor = torch.tensor(X_test, dtype=torch.float32)\n        y_tensor = torch.tensor(y_test, dtype=torch.long)\n        outputs = model(X_tensor)\n        _, predicted = torch.max(outputs.data, 1)\n        accuracy = accuracy_score(y_tensor, predicted)\n        \n        # Log confusion matrix\n        cm = confusion_matrix(y_tensor, predicted)\n        print(f'Confusion Matrix:\\n{cm}')\n        \n        # Log classification report\n        labels = list(label_to_index.keys())\n        report = classification_report(y_tensor, predicted, target_names=labels, labels=np.arange(len(labels)), zero_division=0)\n        print(f'Classification Report:\\n{report}')\n        \n        # Record misclassified examples\n        misclassified_indices = np.where(predicted != y_tensor)[0]\n        for idx in misclassified_indices:\n            misclassified_example = {\n                'text': original_phrases[idx],\n                'true_label': labels[y_test[idx]],\n                'predicted_label': labels[predicted[idx]]\n            }\n            misclassified_examples.append(misclassified_example)\n            print(f'Misclassified Example - Text: {original_phrases[idx]}, True Label: {labels[y_test[idx]]}, Predicted Label: {labels[predicted[idx]]}')\n\n        # Save misclassified examples to JSON file\n        with open(output_json_path, 'w') as f:\n            json.dump(misclassified_examples, f, indent=4)\n        \n        return accuracy, predicted","metadata":{"execution":{"iopub.status.busy":"2024-07-10T18:01:17.738892Z","iopub.execute_input":"2024-07-10T18:01:17.739297Z","iopub.status.idle":"2024-07-10T18:01:17.750242Z","shell.execute_reply.started":"2024-07-10T18:01:17.739263Z","shell.execute_reply":"2024-07-10T18:01:17.749102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Main execution\n\nAlong with exection of the training we will create a function called, plot_confusion_matrix.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\ndef plot_confusion_matrix(y_true, y_pred, labels):\n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure(figsize=(12, 10))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix')\n    plt.show()\n\n# Main code block\nMODEL_PATH = \"/kaggle/working/intent_classifier_nn.pth\"  # Update this to a file path\nOUTPUT_JSON_PATH = \"/kaggle/working/misclassified_examples.json\"  # Path to save the misclassified examples\n\nif not MODEL_PATH:\n    print(f\"Model path is invalid: {MODEL_PATH}\")\n    exit(1)\n\n# Train and save the model\nmodel, vectorizer, label_to_index = train_and_save_model(intent_data, MODEL_PATH)\n\nif model is None:\n    print(\"Model training failed.\")\n    exit(1)\n\n# Load data for validation\nX, y, _, _, original_phrases = load_data(intent_data)\n\n# Validate the model\naccuracy, predicted = validate_model(model, X, y, label_to_index, vectorizer, original_phrases, OUTPUT_JSON_PATH)\nprint(f\"Validation Accuracy: {accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-10T18:01:18.84394Z","iopub.execute_input":"2024-07-10T18:01:18.844891Z","iopub.status.idle":"2024-07-10T18:01:23.822955Z","shell.execute_reply.started":"2024-07-10T18:01:18.844853Z","shell.execute_reply":"2024-07-10T18:01:23.821858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot the Confusion Matrix","metadata":{}},{"cell_type":"code","source":"labels = list(label_to_index.keys())\nplot_confusion_matrix(y, predicted.numpy(), labels)","metadata":{"execution":{"iopub.status.busy":"2024-07-10T18:01:35.263975Z","iopub.execute_input":"2024-07-10T18:01:35.264797Z","iopub.status.idle":"2024-07-10T18:01:37.998192Z","shell.execute_reply.started":"2024-07-10T18:01:35.26476Z","shell.execute_reply":"2024-07-10T18:01:37.997163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Misclassified exapmles","metadata":{}},{"cell_type":"markdown","source":"Now that the misclassifed examples from the validation test are situated nicely in teh misclassified_examples.json, we can grab that json file in the kaggle/working directory, place the items in a df and display them nicely.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nOUTPUT_JSON_PATH = \"/kaggle/working/misclassified_examples.json\"\n\n# Load the misclassified examples from the JSON file\nwith open(OUTPUT_JSON_PATH, 'r') as f:\n    misclassified_examples = json.load(f)\n\n# Convert the misclassified examples to a DataFrame for better visualization\nmisclassified_df = pd.DataFrame(misclassified_examples)\n\n# Display the DataFrame\npd.set_option('display.max_colwidth', None)  # To ensure full text is displayed\ndisplay(misclassified_df)","metadata":{"execution":{"iopub.status.busy":"2024-07-10T18:01:42.204122Z","iopub.execute_input":"2024-07-10T18:01:42.20453Z","iopub.status.idle":"2024-07-10T18:01:42.217791Z","shell.execute_reply.started":"2024-07-10T18:01:42.204497Z","shell.execute_reply":"2024-07-10T18:01:42.216456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}